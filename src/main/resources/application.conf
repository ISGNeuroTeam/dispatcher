spark {
  master = "local"
  appName = "Dispatcher (2.3.1)"
  path_checkpoint = "/opt/otp/dispatcher/checkpoints"
}

schema {
  external_schema = false
  merge_schema = false
}

jdbc {
  driver = "org.postgresql.Driver"
  url = "jdbc:postgresql://localhost:5432/dispatcher"
  username = "dispatcher"
  password = "P@$$w0rd"
}

kafka {
  computing_node_mode_enabled = false
  ip_address = "localhost"
  port = 9092
}

usercommands {
directory = "/home/rkpvteh/src/spark_exec_env/commands"
}

loop {
  pause = 1000 # in millis
  negative_warn_threshold = 10
}

indexes {
  fs_disk = "file:/"
  path_disk = "///mnt/glfs/indexes/"
  fs_cache = "file:/"
  path_cache = "///mnt/g_flow/indexes/"
  duration_cache = 900
  max_cols = 50
  max_mv_size = 20
  max_rows = 100000
  bloom_filename = "bloom"
}

memcache {
  fs = "file:/"
  path = "///mnt/g_cache/caches/"
}

lookups {
  fs = "file:/"
  path = "///mnt/glfs/lookups/"
}

files {
  log_localisation = "/mnt/glfs/configs/dispatcher/log_localisation.conf"
}

searches {
  timeout = 600
}

tracker {
  interval = 5
}